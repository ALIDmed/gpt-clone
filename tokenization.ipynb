{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f0515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf18ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry Potter and the Sorcerers Stone.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af438a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 263976\n",
      "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly norm\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of characters:\", len(raw_text))\n",
    "print(raw_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b113de0",
   "metadata": {},
   "source": [
    "# Classi Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a9f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "    TOKEN_PATTERN = r'([,.:;?\\-!\"()\\']|\\s)'\n",
    "    END_OF_TEXT = \"<|endoftext|>\"\n",
    "    UNKNOWN_TOKEN = \"<|unk|>\"\n",
    "\n",
    "    def __init__(self, raw_text):\n",
    "        self.raw_text = raw_text\n",
    "        self.tokens = self.get_tokens(self.raw_text)\n",
    "\n",
    "    def get_tokens(self, text):\n",
    "        tokens = re.split(self.TOKEN_PATTERN, text)\n",
    "        tokens =[t.strip() for t in tokens if t.strip()]\n",
    "        self.tokens = tokens + [self.END_OF_TEXT, self.UNKNOWN_TOKEN]\n",
    "        self.idx_to_token = {i: t for i, t in enumerate(self.tokens)}\n",
    "        self.token_to_idx = {t: i for i, t in enumerate(self.tokens)}\n",
    "\n",
    "    def encode(self, text):\n",
    "        tokens = re.split(self.TOKEN_PATTERN, text)\n",
    "        tokens = [t.strip() for t in tokens if t.strip()]\n",
    "        return [\n",
    "            self.token_to_idx.get(t, self.token_to_idx[self.UNKNOWN_TOKEN])\n",
    "            for t in tokens\n",
    "        ] + [self.token_to_idx[self.END_OF_TEXT]]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        tokens = [self.idx_to_token[i] for i in indices]\n",
    "        text = \" \".join(tokens)\n",
    "        text = re.sub(r'\\s([,.:;?\\-!\"()\\'])', r\"\\1\", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aee35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [54275, 50599, 51951, 54345, 40688, 54362, 54363]\n",
      "Decoded text: Harry Potter is a wizard. <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(raw_text)\n",
    "\n",
    "text = \"Harry Potter is a wizard.\"\n",
    "encoded = tokenizer.encode(text)\n",
    "\n",
    "print(\"Encoded text:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded text:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706497e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [54275, 50599, 51951, 54263, 54354, 54364, 54362, 54363]\n",
      "Decoded text: Harry Potter is in the <|unk|>. <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Harry Potter is in the palace.\"\n",
    "encoded = tokenizer.encode(text)\n",
    "print(\"Encoded text:\", encoded)\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded text:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c243e4",
   "metadata": {},
   "source": [
    "# Byte pair encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291636e",
   "metadata": {},
   "source": [
    "We have three types of tokenization:\n",
    "\n",
    "**1. Word-level Tokenization:** Splitting text into words based on spaces and punctuation. the problem with this type is out-of-vocabulary (OOV), as well as we might diffrent meaning of similar words for example `[play, played]` or `[boy, boys]`\n",
    "\n",
    "**2. Character based tokenization:** one the advantages of this approach is having small vocabulary size (~256 for english), however, the problem is that we lose the meaning associated with words, and the tokenized sequence is much longer   \n",
    "\n",
    "**3. SubWord-based tokenization:** in this approach we have initialy two rules\n",
    "- Rule 1: do not split frequently used words into smaller subwords.\n",
    "- Rule 2: split rare words into smaller meaningful subwords. (e.g played will be `played` and `ed`)\n",
    "\n",
    "So in general, sub-word tokenization helps the model learn that words with the same root word are similar in meaning e.g `token`, `tokens` and `tokenization`\n",
    "\n",
    "Also, It helps the model learn that `colenization` and `specialization` are made of diffrent root words but have same suffix `ization` and are used in similar syntactic situations.\n",
    "\n",
    "**Byte pair encoding (BPE)** is a sub-word tokenization algorithm\n",
    "\n",
    "*Example*: \n",
    "let's say we have a dataset consists of these words\n",
    "`{\"old\": 7, \"older\": 3, \"lowest\": 4, \"finest\": 9}`\n",
    "- For the preprocessing step we add `<\\w>` at the end of each word:\n",
    "    - `{\"old<\\w>\": 7, \"older<\\w>\": 3, \"lowest<\\w>\": 9, \"finest<\\w>\": 13}`\n",
    "    - then make a character count table \n",
    "    \n",
    "    <img src=\"token-table-1.png\" width=\"400\">\n",
    "\n",
    "    then we look for the most frequent pair of tokens, we merge them and perform the same iteration again & again, until we reach the token limit or iteration limit, in the image below we found that the pair 'es' occur frequent times, so we add it as a new token then we update the occurences\n",
    "\n",
    "    <img src=\"token-table-2.png\" width=\"400\">\n",
    "\n",
    "    then we found that 'est' is most common\n",
    "\n",
    "    <img src=\"token-table-3.png\" width=\"400\">\n",
    "\n",
    "    then 'est<\\w>' *(Note that <\\w> helps the algorithm understand the diffrence between **est**imate and high**est**)*\n",
    "\n",
    "    <img src=\"token-table-4.png\" width=\"400\">  \n",
    "\n",
    "\n",
    "**(To be continued)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cabe71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d7811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1c030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [15496, 703, 389, 345, 30, 220, 50256, 262, 6766, 318, 4171, 13]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello how are you? <|endoftext|> the sky is blue.\"\n",
    "\n",
    "encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(\"Encoded text:\", encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2703cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello how are you? <|endoftext|> the sky is blue.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47081e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Akwirw ier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd0e978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ier'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([959])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6eaeba",
   "metadata": {},
   "source": [
    "## Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "944a84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry Potter and the Sorcerers Stone.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "raw_text = raw_text[53:]\n",
    "enc_text = tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f643266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [22474, 6613, 284, 910]\n",
      "y :      [6613, 284, 910, 326]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "x = enc_text[:context_size]\n",
    "y = enc_text[1:context_size+1]\n",
    "print(f\"x : {x}\")\n",
    "print(f\"y :      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae924ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [22474] ----> target: 6613\n",
      "context: [22474, 6613] ----> target: 284\n",
      "context: [22474, 6613, 284] ----> target: 910\n",
      "context: [22474, 6613, 284, 910] ----> target: 326\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context = enc_text[:i]\n",
    "    target = enc_text[i]\n",
    "    print(f\"context: {context} ----> target: {target}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a6d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: were ----> target:  proud\n",
      "context: were proud ----> target:  to\n",
      "context: were proud to ----> target:  say\n",
      "context: were proud to say ----> target:  that\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context = enc_text[:i]\n",
    "    target = enc_text[i]\n",
    "    print(f\"context: {tokenizer.decode(context)} ----> target: {tokenizer.decode([target])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97190e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text) # Tokenize the entire text\n",
    "\n",
    "        # Create input-target pairs using sliding window\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_seq = token_ids[ i : i+max_length ]\n",
    "            target_seq = token_ids[ i+1 : i+max_length+1 ]\n",
    "            self.input_ids.append(torch.tensor(input_seq))\n",
    "            self.target_ids.append(torch.tensor(target_seq))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7962239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(text, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(text, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=drop_last # drops the last batch if it is shorter than the specified batch_size to prevent loss spikes during training\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f946d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch: [tensor([[  44,  374,   13,  290],\n",
      "        [  13,  290, 9074,   13],\n",
      "        [9074,   13,  360, 1834],\n",
      "        [ 360, 1834, 1636,   11]]), tensor([[ 374,   13,  290, 9074],\n",
      "        [ 290, 9074,   13,  360],\n",
      "        [  13,  360, 1834, 1636],\n",
      "        [1834, 1636,   11,  286]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Harry Potter and the Sorcerers Stone.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# NOTE: If we set the stride equal to the input window size, we can prevent overlaps between the batches\n",
    "dataloader = create_data_loader(raw_text, max_length=4, stride=2, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "first_batch = next(data_iter)\n",
    "\n",
    "print(f\"first batch: {first_batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d949a",
   "metadata": {},
   "source": [
    "## Creating token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504ece0",
   "metadata": {},
   "source": [
    "We initialize the embedding weights with random values as a preliminary step. This initialization serves as the starting point for the LLM's learning process. We will optimize the embedding weights later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f33404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "inputs_ids = torch.tensor([2, 5, 3, 5])\n",
    "\n",
    "vocab_size = 6 \n",
    "output_dim = 3 # embedding size\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a9b946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2753, -0.2010, -0.1606],\n",
       "        [-2.8400, -0.7849, -1.4096],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-2.8400, -0.7849, -1.4096]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(inputs_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30adeb",
   "metadata": {},
   "source": [
    "## Encoding word positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3d5e2",
   "metadata": {},
   "source": [
    "The self-attention mechanism , doesn't have a notion of position or order for the tokens within a sequence.\n",
    "The way the previously introduced embedding layer works is that the same token ID always gets mapped to the same vector representation, regardless of where the token ID is\n",
    "positioned in the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023e247",
   "metadata": {},
   "source": [
    "Absolute positional embeddings are directly associated with specific positions in a sequence. For each position in the input sequence, a unique embedding is added to the\n",
    "token's embedding to convey its exact location. For instance, the first token will have a specific positional embedding, the second token another distinct embedding, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481655b",
   "metadata": {},
   "source": [
    "Instead of focusing on the absolute position of a token, the emphasis of relative positional embeddings is on the relative position or distance between tokens. **This means the model\n",
    "learns the relationships in terms of \"how far apart\" rather than \"at which exact position.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f288ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   44,   374,    13,   290],\n",
      "        [ 9074,    13,   360,  1834],\n",
      "        [ 1636,    11,   286,  1271],\n",
      "        [ 1440,    11,  4389, 16809],\n",
      "        [ 9974,    11,   547,  6613],\n",
      "        [  284,   910,   326,   484],\n",
      "        [  547,  7138,  3487,    11],\n",
      "        [ 5875,   345,   845,   881]])\n",
      "Input shape: torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.n_vocab\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "max_length = 4\n",
    "\n",
    "dataloader = create_data_loader(\n",
    "    text=raw_text,\n",
    "    batch_size=8,\n",
    "    max_length=max_length,\n",
    "    stride=max_length,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(f\"Token IDs:\\n {inputs}\")\n",
    "print(f\"Input shape: {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4140640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = token_embedding_layer(inputs)\n",
    "token_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1289d",
   "metadata": {},
   "source": [
    "The input to the pos_embeddings is usually a placeholder vector torch.arange(context_length), which contains a sequence of\n",
    "numbers 0, 1, ..., up to the maximum input length âˆ’ 1. The context_length is a variable\n",
    "that represents the supported input size of the LLM. Here, we choose it similar to the\n",
    "maximum length of the input text. In practice, input text can be longer than the supported\n",
    "context length, in which case we have to truncate the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29dda3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becda4df",
   "metadata": {},
   "source": [
    "As we can see, the positional embedding tensor consists of four 256-dimensional vectors.\n",
    "We can now add these directly to the token embeddings, where PyTorch will add the 4x256-\n",
    "dimensional pos_embeddings tensor to each 4x256-dimensional token embedding tensor in\n",
    "each of the 8 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a41382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = token_embedding + pos_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928e940",
   "metadata": {},
   "source": [
    "**While token embeddings provide consistent vector representations for\n",
    "each token, they lack a sense of the token's position in a sequence. To\n",
    "rectify this, two main types of positional embeddings exist: absolute and\n",
    "relative. OpenAI's GPT models utilize absolute positional embeddings that\n",
    "are added to the token embedding vectors and are optimized during the\n",
    "model training.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
